{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seon03/ArtificialIntelligence/blob/main/(2%E1%84%80%E1%85%A1%E1%86%BC_%E1%84%89%E1%85%B5%E1%86%AF%E1%84%89%E1%85%B3%E1%86%B8)_Multi_Layer_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0aqRluNsI38"
      },
      "source": [
        "# Multilayer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXxbX-Diq9rq",
        "outputId": "f142b968-4bf3-433a-ba92-888d6686f2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print (\"device:[%s].\"%(device))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:[2.3.1+cu121].\n",
            "device:[cuda:0].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HWvC0ZltF8a"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaokkwJwsN5I",
        "outputId": "d7a75b9b-afe6-411a-cbe8-3f8599d51af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchvision import datasets,transforms\n",
        "mnist_train = datasets.MNIST(root='./data/',train=True,transform=transforms.ToTensor(),download=True)\n",
        "mnist_test = datasets.MNIST(root='./data/',train=False,transform=transforms.ToTensor(),download=True)\n",
        "print (\"mnist_train:\\n\",mnist_train,\"\\n\")\n",
        "print (\"mnist_test:\\n\",mnist_test,\"\\n\")\n",
        "print (\"Done.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:10<00:00, 905407.64it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 56461.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:06<00:00, 237347.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 10942291.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "mnist_train:\n",
            " Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor() \n",
            "\n",
            "mnist_test:\n",
            " Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data/\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor() \n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4lP2QQoBXGw"
      },
      "source": [
        "### Data Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0TKrHSCBWzm",
        "outputId": "97608741-ecab-4934-da7c-579f9477c5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "train_iter = torch.utils.data.DataLoader(mnist_train,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
        "test_iter = torch.utils.data.DataLoader(mnist_test,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
        "print (\"Done.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081T7_3lvk-N"
      },
      "source": [
        "### Define the MLP model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4mWpPXouPCR",
        "outputId": "a1d9f5ed-1ed4-4ddf-9f33-de15296b6902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class MultiLayerPerceptronClass(nn.Module):\n",
        "    \"\"\"\n",
        "        Multilayer Perceptron (MLP) Class\n",
        "    \"\"\"\n",
        "    def __init__(self,name='mlp',xdim=784,hdim=256,ydim=10):\n",
        "        super(MultiLayerPerceptronClass,self).__init__()\n",
        "        self.name = name\n",
        "        self.xdim = xdim\n",
        "        self.hdim = hdim\n",
        "        self.ydim = ydim\n",
        "        self.lin_1 = nn.Linear(self.xdim,self.hdim)\n",
        "        self.lin_2 = nn.Linear(self.hdim,self.ydim)\n",
        "        self.init_param() # initialize parameters\n",
        "\n",
        "    def init_param(self):\n",
        "        nn.init.kaiming_normal_(self.lin_1.weight)\n",
        "        nn.init.zeros_(self.lin_1.bias)\n",
        "        nn.init.kaiming_normal_(self.lin_2.weight)\n",
        "        nn.init.zeros_(self.lin_2.bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "        net = x\n",
        "        net = self.lin_1(net)\n",
        "        net = F.relu(net)\n",
        "        net = self.lin_2(net)\n",
        "        return net\n",
        "\n",
        "M = MultiLayerPerceptronClass(name='mlp',xdim=784,hdim=256,ydim=10).to(device)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optm = optim.Adam(M.parameters(),lr=1e-3)\n",
        "print (\"Done.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrPPFQi56NDk"
      },
      "source": [
        "### Simple Forward Path of the MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rOz8a1Gw1Xi",
        "outputId": "5a781b94-98bb-4b9a-efd8-8e39238d55ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_numpy = np.random.rand(2,784)\n",
        "x_torch = torch.from_numpy(x_numpy).float().to(device)\n",
        "y_torch = M.forward(x_torch) # forward path\n",
        "y_numpy = y_torch.detach().cpu().numpy() # torch tensor to numpy array\n",
        "print (\"x_numpy:\\n\",x_numpy)\n",
        "print (\"x_torch:\\n\",x_torch)\n",
        "print (\"y_torch:\\n\",y_torch)\n",
        "print (\"y_numpy:\\n\",y_numpy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_numpy:\n",
            " [[0.09728812 0.88543882 0.83880107 ... 0.59986395 0.47660489 0.45562567]\n",
            " [0.24202313 0.08093866 0.24463584 ... 0.94345583 0.67729349 0.05721118]]\n",
            "x_torch:\n",
            " tensor([[0.0973, 0.8854, 0.8388,  ..., 0.5999, 0.4766, 0.4556],\n",
            "        [0.2420, 0.0809, 0.2446,  ..., 0.9435, 0.6773, 0.0572]],\n",
            "       device='cuda:0')\n",
            "y_torch:\n",
            " tensor([[ 1.5324, -0.2018,  1.0658, -0.2011,  0.2716, -0.5253, -0.3176,  0.1551,\n",
            "          0.8550, -1.5424],\n",
            "        [ 1.6835, -0.2691,  1.5798,  0.1629,  1.8021, -0.7128, -0.1664,  0.0844,\n",
            "          1.0658, -0.8549]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "y_numpy:\n",
            " [[ 1.532354   -0.20179313  1.0658259  -0.20111892  0.27156365 -0.5253175\n",
            "  -0.31757247  0.15513468  0.85499346 -1.5423629 ]\n",
            " [ 1.6834854  -0.26908058  1.579822    0.16294     1.802095   -0.7128019\n",
            "  -0.16642286  0.08442896  1.0657705  -0.85491186]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzd12JKl7NpX"
      },
      "source": [
        "### Check Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rmd2r_kw1s0",
        "outputId": "a9e48b29-00e9-46b5-95aa-64a2b6455f22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.set_printoptions(precision=3)\n",
        "n_param = 0\n",
        "for p_idx,(param_name,param) in enumerate(M.named_parameters()):\n",
        "    param_numpy = param.detach().cpu().numpy()\n",
        "    n_param += len(param_numpy.reshape(-1))\n",
        "    print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n",
        "    print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
        "print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] name:[lin_1.weight] shape:[(256, 784)].\n",
            "    val:[ 0.001  0.05  -0.028  0.003  0.094]\n",
            "[1] name:[lin_1.bias] shape:[(256,)].\n",
            "    val:[0. 0. 0. 0. 0.]\n",
            "[2] name:[lin_2.weight] shape:[(10, 256)].\n",
            "    val:[ 0.112  0.038  0.119 -0.01  -0.086]\n",
            "[3] name:[lin_2.bias] shape:[(10,)].\n",
            "    val:[0. 0. 0. 0. 0.]\n",
            "Total number of parameters:[203,530].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVaqrcXUA5EB"
      },
      "source": [
        "### Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxXyYXH75Veq",
        "outputId": "4a4470bd-44e4-429c-df58-256a38c8bd18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def func_eval(model,data_iter,device):\n",
        "    with torch.no_grad():\n",
        "        model.eval() # evaluate (affects DropOut and BN)\n",
        "        n_total,n_correct = 0,0\n",
        "        for batch_in,batch_out in data_iter:\n",
        "            y_trgt = batch_out.to(device)\n",
        "            model_pred = model(batch_in.view(-1,28*28).to(device))\n",
        "            _,y_pred = torch.max(model_pred.data,1)\n",
        "            n_correct += (y_pred==y_trgt).sum().item()\n",
        "            n_total += batch_in.size(0)\n",
        "        val_accr = (n_correct/n_total)\n",
        "        model.train() # back to train mode\n",
        "    return val_accr\n",
        "print (\"Done\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmmJjAFKKOrB"
      },
      "source": [
        "### Initial Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNlGD1TlA4T8",
        "outputId": "2a79be13-7798-4854-8493-b8fdcc833bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.init_param() # initialize parameters\n",
        "train_accr = func_eval(M,train_iter,device)\n",
        "test_accr = func_eval(M,test_iter,device)\n",
        "print (\"train_accr:[%.3f] test_accr:[%.3f].\"%(train_accr,test_accr))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_accr:[0.105] test_accr:[0.105].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT_r2wMZLjTm"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AS5BdrMw1E9",
        "outputId": "f058d7da-9255-4054-931c-426e6356c152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (\"Start training.\")\n",
        "M.init_param() # initialize parameters\n",
        "M.train()\n",
        "EPOCHS,print_every = 10,1\n",
        "for epoch in range(EPOCHS):\n",
        "    loss_val_sum = 0\n",
        "    for batch_in,batch_out in train_iter:\n",
        "        # Forward path\n",
        "        y_pred = M.forward(batch_in.view(-1, 28*28).to(device))\n",
        "        loss_out = loss(y_pred,batch_out.to(device))\n",
        "        # Update\n",
        "        optm.zero_grad()      # reset gradient\n",
        "        loss_out.backward()     # backpropagate\n",
        "        optm.step()      # optimizer update\n",
        "        loss_val_sum += loss_out\n",
        "    loss_val_avg = loss_val_sum/len(train_iter)\n",
        "    # Print\n",
        "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
        "        train_accr = func_eval(M,train_iter,device)\n",
        "        test_accr = func_eval(M,test_iter,device)\n",
        "        print (\"epoch:[%d] loss:[%.3f] train_accr:[%.3f] test_accr:[%.3f].\"%\n",
        "               (epoch,loss_val_avg,train_accr,test_accr))\n",
        "print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training.\n",
            "epoch:[0] loss:[0.383] train_accr:[0.947] test_accr:[0.946].\n",
            "epoch:[1] loss:[0.164] train_accr:[0.965] test_accr:[0.962].\n",
            "epoch:[2] loss:[0.117] train_accr:[0.973] test_accr:[0.968].\n",
            "epoch:[3] loss:[0.090] train_accr:[0.980] test_accr:[0.973].\n",
            "epoch:[4] loss:[0.072] train_accr:[0.984] test_accr:[0.976].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHQIhg-aNok5"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52zoFQxdMWRU"
      },
      "source": [
        "n_sample = 25\n",
        "sample_indices = np.random.choice(len(mnist_test.targets), n_sample, replace=False)\n",
        "test_x = mnist_test.data[sample_indices]\n",
        "test_y = mnist_test.targets[sample_indices]\n",
        "with torch.no_grad():\n",
        "    y_pred = M.forward(test_x.view(-1, 28*28).type(torch.float).to(device)/255.)\n",
        "y_pred = y_pred.argmax(axis=1)\n",
        "plt.figure(figsize=(10,10))\n",
        "for idx in range(n_sample):\n",
        "    plt.subplot(5, 5, idx+1)\n",
        "    plt.imshow(test_x[idx], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Pred:%d, Label:%d\"%(y_pred[idx],test_y[idx]))\n",
        "plt.show()\n",
        "print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikf5C7uV_ExD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**콘텐츠 라이선스**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "PeVYUcJKZqyR"
      }
    }
  ]
}